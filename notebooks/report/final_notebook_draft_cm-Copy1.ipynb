{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report and Summary of Analysis: Improving Timely Diagnoses in Medical Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONTENTS\n",
    "\n",
    "    I. Purpose\n",
    "    II. Data and Context\n",
    "    III. Model Creation\n",
    "    IV. Evaluate Results\n",
    "    V. Recommendations\n",
    "    VI. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import src.functions as fn\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Purpose\n",
    "\n",
    "Applications of technology in the field of medicine have come in many forms, including equipment and procedural advancements. With the goal of improving the quality of health and care that is delivered to patients, the purpose of this notebook is to explore the use of Neural Networks in medical imaging to aid in the timely diagnoses to those who need it most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal:\n",
    "\n",
    "Build a tool that uses a Convolutional Neural Network (CNN) to assist in diagnosing patients with Pneumonia. This Neural Network will reliably identify patients with pneumonia so radiologists and doctors can prioritize those patients for quicker review, diagnoses, and treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data and Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data comes from Guangzhou Women and Childrenâ€™s Medical Center. The original data set can be found [here](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).\n",
    "- Reviewed by two physicians to confirm the accuracy of the diagnoses. \n",
    "- Includes bacterial and viral pneumonia.\n",
    "- Uses anterior and posterior ex-ray views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "While exploring the image data set, we discovered that a number of images in the pneumonia data set had visible medical equipment, while very few of the healthy lung images had such medical equipment. \n",
    "\n",
    "Here is a pneumonic lung x-ray with what appears to be an IV in the upper right corner of the image, and an electrode on the upper left, along with some type of tubing to the left of the heart and across the lower ribcage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../references/person109_bacteria_519.jpeg\" alt=\"drawing\" width=\"400\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another x-ray of a pneumonic lung, this time with no visible medical euipment. We would consider this a clean image.\n",
    "\n",
    "<img src=\"../../references/person3_virus_15.jpeg\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why does this matter?\n",
    "We want to make sure that our model is examining lungs for signs of pneumonia in a similar manner to an actual physician or radiologist. With this medical equipment being so prevelant in the pneumonic lung images, we may inadvertantly train our model to interpret medical equipment as a sign of pneuomonia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "We went through each image in the training data and manually deleted all x-rays that appeared to have medical equipment in them. This cut out about 1500 images unfortunately, but we determined this was worth it in order to prevent a model from learning incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Build First Simple Model\n",
    "     - Evaluate\n",
    "    2. Build additional models using a variety of methods and architechtures\n",
    "     - Optimize for Recall and Accuracy\n",
    "     - Review results and explore new approaches for feature engineering\n",
    "     - Repeat steps 3 and 4\n",
    "     - Choose the best model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build First Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2568 images belonging to 2 classes.\n",
      "Found 550 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = fn.load_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters:\n",
    "- Layers:\n",
    " - Flatten layer\n",
    "   - Note on input shape: The data generators for this model provided images that were greyscale at dimensions 100x100\n",
    " - Dense layer with 85 nodes and ReLU activation\n",
    " - Output layer\n",
    "- Optimizer: Adam\n",
    "- Loss: binary crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(100,100,1)))\n",
    "model.add(Dense(units=85, \n",
    "                activation='relu'))\n",
    "model.add(Dense(units=1, \n",
    "                activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model\n",
    "#### This cell may take more than 10 minutes to run\n",
    "- Trained for 10 epochs\n",
    "- Number of steps is set equal to the length of the data generator which means it will run through every image at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "81/81 [==============================] - 54s 662ms/step - loss: 0.9850 - accuracy: 0.6351 - precision: 0.6430 - recall: 0.7813 - val_loss: 0.5532 - val_accuracy: 0.7873 - val_precision: 0.7922 - val_recall: 0.8918\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 51s 625ms/step - loss: 0.5194 - accuracy: 0.7640 - precision: 0.7470 - recall: 0.8740 - val_loss: 0.4885 - val_accuracy: 0.8091 - val_precision: 0.8937 - val_recall: 0.7865\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 48s 596ms/step - loss: 0.4450 - accuracy: 0.8053 - precision: 0.7951 - recall: 0.8781 - val_loss: 0.4188 - val_accuracy: 0.8364 - val_precision: 0.8795 - val_recall: 0.8538\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 45s 552ms/step - loss: 0.4062 - accuracy: 0.8220 - precision: 0.8266 - recall: 0.8628 - val_loss: 0.3583 - val_accuracy: 0.8527 - val_precision: 0.8896 - val_recall: 0.8713\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 44s 548ms/step - loss: 0.3967 - accuracy: 0.8252 - precision: 0.8262 - recall: 0.8705 - val_loss: 0.3398 - val_accuracy: 0.8600 - val_precision: 0.9003 - val_recall: 0.8713\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 44s 545ms/step - loss: 0.3650 - accuracy: 0.8388 - precision: 0.8402 - recall: 0.8788 - val_loss: 0.3217 - val_accuracy: 0.8600 - val_precision: 0.9077 - val_recall: 0.8626\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 44s 547ms/step - loss: 0.3651 - accuracy: 0.8407 - precision: 0.8421 - recall: 0.8802 - val_loss: 0.3286 - val_accuracy: 0.8545 - val_precision: 0.8484 - val_recall: 0.9327\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 45s 551ms/step - loss: 0.3759 - accuracy: 0.8294 - precision: 0.8345 - recall: 0.8670 - val_loss: 0.3223 - val_accuracy: 0.8509 - val_precision: 0.8631 - val_recall: 0.9035\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 52s 646ms/step - loss: 0.3690 - accuracy: 0.8392 - precision: 0.8482 - recall: 0.8677 - val_loss: 0.3502 - val_accuracy: 0.8582 - val_precision: 0.9521 - val_recall: 0.8129\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 45s 559ms/step - loss: 0.3351 - accuracy: 0.8590 - precision: 0.8628 - recall: 0.8893 - val_loss: 0.3047 - val_accuracy: 0.8636 - val_precision: 0.8698 - val_recall: 0.9181\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, \n",
    "                    epochs=10, \n",
    "                    validation_data=(val_data), \n",
    "                    steps_per_epoch=len(train_data), \n",
    "                    validation_steps=len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 5s 266ms/step - loss: 0.3890 - accuracy: 0.8157 - precision: 0.8022 - recall: 0.9359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('loss', 0.3890226185321808),\n",
       " ('accuracy', 0.8157051205635071),\n",
       " ('precision', 0.8021978139877319),\n",
       " ('recall', 0.9358974099159241)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = model.evaluate(test_data, steps=len(test_data), verbose=1)\n",
    "list(zip(model.metrics_names, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building Additional Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
